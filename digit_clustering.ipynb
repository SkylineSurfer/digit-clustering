{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNaVFL85gsOgTTwuTfrt7G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SkylineSurfer/digit-clustering/blob/main/digit_clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WbtIZfbXPA2"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_competition= pd.read_csv('data.csv')\n",
        "data_competition.head()"
      ],
      "metadata": {
        "id": "g00CF9WcXWdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ID=data_competition['ID']\n",
        "data_competition= data_competition.drop(['ID'], axis=1)\n",
        "data_competition= preprocessing.normalize(data_competition, axis=0)\n",
        "type(data_competition)"
      ],
      "metadata": {
        "id": "UQ_1Hj9QXWga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "tsne = TSNE(n_components=2, perplexity=30, random_state=0)\n",
        "data_reduced = tsne.fit_transform(data_scaled)\n"
      ],
      "metadata": {
        "id": "iElKt4KeXWjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply PCA for dimensionality reduction\n",
        "pca = PCA(n_components=2, random_state=0)  # Choose the number of components as needed\n",
        "reduced_data = pca.fit_transform(data_scaled)\n",
        "\n",
        "# Apply K-Means Clustering on the reduced-dimensional data\n",
        "kmeans = KMeans(n_clusters=12)  # Change the number of clusters as needed\n",
        "\n",
        "labels= kmeans.fit_predict(reduced_data)\n",
        "\n",
        "# Now you have your cluster labels in 'cluster_labels'\n",
        "# You can further analyze your clusters or visualize them as needed\n"
      ],
      "metadata": {
        "id": "fIkXPh0NXWlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the clusters\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot each cluster\n",
        "for cluster in range(kmeans.n_clusters):\n",
        "    cluster_data = reduced_data[labels == cluster]\n",
        "    plt.scatter(cluster_data[:, 0], cluster_data[:, 1], label=f'Cluster {cluster}')\n",
        "\n",
        "# Plot the cluster centers\n",
        "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], marker='x', color='black', label='Cluster Centers')\n",
        "\n",
        "plt.title('K-Means Clustering after PCA')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1CXL9qB9XWoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Fit the t-SNE model to your normalized data\n",
        "\n",
        "tsne_data = tsne.fit_transform(data_reduced)  # Assuming you've already normalized your data\n",
        "\n",
        "# Convert the t-SNE transformed data to a DataFrame\n",
        "tsne_df = pd.DataFrame(tsne_data, columns=['t-SNE Component 1', 't-SNE Component 2'])\n",
        "\n",
        "# Plot the t-SNE results\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(tsne_df['t-SNE Component 1'], tsne_df['t-SNE Component 2'], alpha=0.5)\n",
        "plt.title('t-SNE Visualization')\n",
        "plt.xlabel('t-SNE Component 1')\n",
        "plt.ylabel('t-SNE Component 2')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tZQUihaDXWq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming data_reduced is your reduced-dimensional data from PCA\n",
        "\n",
        "# Apply k-means clustering\n",
        "#k = 12 # Example: number of clusters\n",
        "#kmeans_tsne = KMeans(n_clusters=k,random_state=42)\n",
        "kmeans_tsne =KMeans(init='k-means++', n_clusters=12, n_init=60)\n",
        "kmeans_tsne.fit(data_reduced)\n",
        "\n",
        "# Predict the cluster labels for each data point\n",
        "'''********************************'''\n",
        "labels = kmeans_tsne.predict(data_reduced)\n",
        "\n",
        "# Get the centroids\n",
        "centroids_tsne = kmeans_tsne.cluster_centers_\n",
        "\n",
        "# Print the centroids\n",
        "print(\"Centroids:\")\n",
        "print(centroids_tsne)\n",
        "\n",
        "# Print the cluster labels for each data point\n",
        "print(\"Cluster Labels:\")\n",
        "print(labels)\n"
      ],
      "metadata": {
        "id": "YyGmB0aEXWtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the reduced data points\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(data_reduced[:, 0], data_reduced[:, 1], c=kmeans_tsne.labels_, cmap='viridis', s=10, alpha=0.5)\n",
        "plt.scatter(centroids_tsne[:, 0], centroids_tsne[:, 1], marker='x', c='red', s=100, label='Centroids')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.title('t-SNE & K-Means Clustering')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2UE4CQ91XWwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "\n",
        "# Assuming data_competition is your dataset with 784 columns\n",
        "\n",
        "# Instantiate the KMeans model with explicit n_init\n",
        "kmeans_tsne = KMeans(n_init=10)\n",
        "\n",
        "# Create the elbow visualizer\n",
        "visualizer_tsne = KElbowVisualizer(kmeans_tsne, k=(1, 14))\n",
        "\n",
        "# Fit the visualizer to the data\n",
        "visualizer_tsne.fit(data_competition)\n",
        "\n",
        "# Show the plot\n",
        "visualizer_tsne.show()\n"
      ],
      "metadata": {
        "id": "3ESZjmN1XWy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add\n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "# Assuming `data_reduced` is your t-SNE reduced data\n",
        "# Determine the optimal number of components using BIC\n",
        "n_components_range = np.arange(1, 13)\n",
        "\n",
        "bic = []\n",
        "lowest_bic = np.infty\n",
        "best_gmm = None\n",
        "\n",
        "for n_components in n_components_range:\n",
        "    gmm = GaussianMixture(n_components=n_components, covariance_type='full', random_state=0)\n",
        "    gmm.fit(data_reduced)\n",
        "    bic_score = gmm.bic(data_reduced)\n",
        "    bic.append(bic_score)\n",
        "    if bic_score < lowest_bic:\n",
        "        lowest_bic = bic_score\n",
        "        best_gmm = gmm\n",
        "\n",
        "# Plot the BIC scores\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(n_components_range, bic, marker='o')\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('BIC')\n",
        "plt.title('BIC Scores for Different Number of Components')\n",
        "plt.show()\n",
        "\n",
        "# Use the best GMM to predict the clusters\n",
        "'''*********************************'''\n",
        "#labels = best_gmm.predict(data_reduced)\n"
      ],
      "metadata": {
        "id": "gibPY6PmXW4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = best_gmm.predict(data_reduced)\n",
        "\n",
        "\n",
        "# Print the cluster labels for each data point\n",
        "print(\"Cluster Labels:\")\n",
        "print(labels)\n"
      ],
      "metadata": {
        "id": "iw-lDwreXW7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import IncrementalPCA\n",
        "import numpy as np\n",
        "\n",
        "# Generate example data (replace this with your data)\n",
        "n_samples, n_features = 1000, 785\n",
        "X = np.random.randn(n_samples, n_features)\n",
        "\n",
        "# Initialize IPCA with the desired number of components\n",
        "n_components = 3\n",
        "ipca = IncrementalPCA(n_components=n_components)\n",
        "\n",
        "# Process batches of data (e.g., streaming or mini-batch processing)\n",
        "batch_size = 100\n",
        "for i in range(0, len(X), batch_size):\n",
        "    X_batch = X[i:i+batch_size]\n",
        "    ipca.partial_fit(X_batch)\n",
        "\n",
        "# Retrieve the principal components\n",
        "principal_components = ipca.components_\n",
        "\n",
        "# Transform the data using the learned principal components\n",
        "X_transformed = ipca.transform(X)\n",
        "\n",
        "# Print the transformed data\n",
        "print(\"Transformed Data:\")\n",
        "print(X_transformed)\n"
      ],
      "metadata": {
        "id": "DftRB-EAXW-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming data_competition is your NumPy array\n",
        "\n",
        "# Convert the NumPy array to a DataFrame\n",
        "df_competition = pd.DataFrame(data_competition)\n",
        "\n",
        "# Specify the file path for saving the Excel file"
      ],
      "metadata": {
        "id": "CPSXiY7rdqui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming data_competition is your NumPy array and labels is your cluster labels array\n",
        "\n",
        "# Convert the NumPy array to a DataFrame\n",
        "df_competition = pd.DataFrame(data_competition)\n",
        "\n",
        "# Create a DataFrame for the labels\n",
        "df_labels = pd.DataFrame({'label': labels})\n",
        "\n",
        "# Concatenate the \"ID\" column with the labels DataFrame\n",
        "_df = pd.concat([ID, df_labels], axis=1)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "_df.to_csv('sample_submission.csv', index=False)\n"
      ],
      "metadata": {
        "id": "Uk1ywMAPXXAb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}